import type { Express, Request, Response } from "express";
import { voiceChat, transcribeAudio } from "./client";
import { db } from "../../db";
import { agents, businesses, conversations, messages, usageLogs } from "@shared/schema";
import { eq, and, desc, sql } from "drizzle-orm";

export function registerAudioRoutes(app: Express) {
  app.use("/api/voice", (req, res, next) => {
    const limit = "50mb";
    require("express").json({ limit })(req, res, next);
  });

  app.post("/api/voice/chat", async (req: Request, res: Response) => {
    try {
      const { audioBase64, agentId, conversationId, businessId } = req.body;

      if (!audioBase64) {
        return res.status(400).json({ error: "Audio data is required" });
      }

      if (!agentId || !businessId) {
        return res.status(400).json({ error: "Agent ID and Business ID are required" });
      }

      const [agent] = await db.select().from(agents).where(eq(agents.id, agentId));
      if (!agent) {
        return res.status(404).json({ error: "Agent not found" });
      }

      const [business] = await db.select().from(businesses).where(eq(businesses.id, businessId));
      if (!business) {
        return res.status(404).json({ error: "Business not found" });
      }

      let convId = conversationId;
      if (!convId) {
        const [newConversation] = await db.insert(conversations).values({
          businessId,
          agentId,
          status: "active",
          channel: "voice",
          contactPhone: "in-app-voice",
        }).returning();
        convId = newConversation.id;
      }

      const previousMessages = await db.select()
        .from(messages)
        .where(eq(messages.conversationId, convId))
        .orderBy(desc(messages.createdAt))
        .limit(10);

      const history = previousMessages.reverse().map(msg => ({
        role: msg.role === "user" ? "user" : "assistant",
        content: msg.content
      }));

      const systemPrompt = buildSystemPrompt(agent, business);

      // Start processing voice chat
      const result = await voiceChat(audioBase64, systemPrompt, history);

      let userText = result.userTranscript || "[Voice input]";
      
      // Update DB asynchronously to avoid blocking the response if possible
      // but we need the convId. We already have it.
      
      const saveMessages = async () => {
        try {
          await db.insert(messages).values({
            conversationId: convId,
            content: userText,
            role: "user",
            wasAutoGenerated: false,
          });

          await db.insert(messages).values({
            conversationId: convId,
            content: result.transcript,
            role: "agent",
            wasAutoGenerated: true,
          });

          await db.update(conversations)
            .set({ updatedAt: new Date() })
            .where(eq(conversations.id, convId));
        } catch (e) {
          console.error("[Voice Chat] DB Save Error:", e);
        }
      };
      
      saveMessages(); // Fire and forget for faster response

      // Log usage for voice chat (calculating as 1 credit for now to match UI, but model is cheaper)
      try {
        await db.insert(usageLogs).values({
          businessId,
          type: "voice_minute",
          quantity: 1,
          creditsUsed: 1, // You can adjust this to fractional if you support decimals in your credits
        });
        
        await db.update(businesses)
          .set({ aiCreditsRemaining: sql`${businesses.aiCreditsRemaining} - 1` })
          .where(eq(businesses.id, businessId));
      } catch (e) {
        console.error("[Voice Chat] Usage Log Error:", e);
      }

      res.json({
        success: true,
        conversationId: convId,
        audioBase64: result.audioBase64,
        transcript: result.transcript,
        userTranscript: userText,
      });
    } catch (error: any) {
      console.error("[Voice Chat] Error:", error);
      res.status(500).json({ error: error.message || "Voice processing failed" });
    }
  });

  app.post("/api/voice/transcribe", async (req: Request, res: Response) => {
    try {
      const { audioBase64 } = req.body;

      if (!audioBase64) {
        return res.status(400).json({ error: "Audio data is required" });
      }

      const transcript = await transcribeAudio(audioBase64);

      res.json({ success: true, transcript });
    } catch (error: any) {
      console.error("[Transcribe] Error:", error);
      res.status(500).json({ error: error.message || "Transcription failed" });
    }
  });

  app.get("/api/voice/agents/:businessId", async (req: Request, res: Response) => {
    try {
      const { businessId } = req.params;
      
      const agentList = await db.select()
        .from(agents)
        .where(eq(agents.businessId, businessId));

      res.json(agentList);
    } catch (error: any) {
      console.error("[Voice Agents] Error:", error);
      res.status(500).json({ error: "Failed to fetch agents" });
    }
  });
}

function buildSystemPrompt(agent: any, business: any): string {
  const basePrompt = agent.systemPrompt || `You are a helpful AI assistant for ${business.name}.`;
  
  const knowledgeBase = agent.knowledgeBase || "";
  
  const modeInstructions = agent.pilotMode === "off" 
    ? "You should only transfer calls to human agents, do not make decisions."
    : agent.pilotMode === "suggestive"
    ? "Provide suggestions but ask for confirmation before taking actions."
    : "You can autonomously handle customer requests.";

  return `${basePrompt}

Business: ${business.name}
${business.website ? `Website: ${business.website}` : ""}

Mode: ${modeInstructions}

${knowledgeBase ? `Knowledge Base:\n${knowledgeBase}` : ""}

Voice Guidelines:
- Keep responses concise and natural for spoken conversation
- Use conversational language, avoid jargon
- If you don't understand, politely ask for clarification
- Be helpful, friendly, and professional`;
}
